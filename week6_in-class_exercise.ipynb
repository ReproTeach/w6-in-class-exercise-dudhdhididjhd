{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd6130c2-3a8c-4401-ae9b-c8cc743a074b",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis on Social Media Data\n",
    "\n",
    "by Andrew Chang, Chloe Din-Luong\n",
    "\n",
    "The data is in uncleaned format and is collected using Twitter API. The Tweets has been filtered to keep only the English context. It targets mental health classification of the user at Tweet-level. This project will demonstrate data cleaning in order to begin an Exploratory Data Analysis on Social Media Data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603a40a3-9ea2-4d3f-a8c5-2d98336ec4bc",
   "metadata": {},
   "source": [
    "## 1. Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8308e587-737b-44aa-b3ee-de8542e973f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import emoji\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d4a085-74e8-4093-85e4-9a2f8008bf04",
   "metadata": {},
   "source": [
    "## 2. Read the data\n",
    "\n",
    "The data is called `tweets.csv` in the same folder. More information about the data see [here](https://www.kaggle.com/datasets/infamouscoder/mental-health-social-media)\n",
    "\n",
    "The main column you will be working with is `post_text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c10a6b2a-52c4-4409-ba19-f199bff034b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Unnamed: 0    20000 non-null  int64 \n",
      " 1   post_id       20000 non-null  int64 \n",
      " 2   post_created  20000 non-null  object\n",
      " 3   post_text     20000 non-null  object\n",
      " 4   user_id       20000 non-null  int64 \n",
      " 5   followers     20000 non-null  int64 \n",
      " 6   friends       20000 non-null  int64 \n",
      " 7   favourites    20000 non-null  int64 \n",
      " 8   statuses      20000 non-null  int64 \n",
      " 9   retweets      20000 non-null  int64 \n",
      " 10  label         20000 non-null  int64 \n",
      "dtypes: int64(9), object(2)\n",
      "memory usage: 1.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_created</th>\n",
       "      <th>post_text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>followers</th>\n",
       "      <th>friends</th>\n",
       "      <th>favourites</th>\n",
       "      <th>statuses</th>\n",
       "      <th>retweets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>637894677824413696</td>\n",
       "      <td>Sun Aug 30 07:48:37 +0000 2015</td>\n",
       "      <td>It's just over 2 years since I was diagnosed w...</td>\n",
       "      <td>1013187241</td>\n",
       "      <td>84</td>\n",
       "      <td>211</td>\n",
       "      <td>251</td>\n",
       "      <td>837</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>637890384576778240</td>\n",
       "      <td>Sun Aug 30 07:31:33 +0000 2015</td>\n",
       "      <td>It's Sunday, I need a break, so I'm planning t...</td>\n",
       "      <td>1013187241</td>\n",
       "      <td>84</td>\n",
       "      <td>211</td>\n",
       "      <td>251</td>\n",
       "      <td>837</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>637749345908051968</td>\n",
       "      <td>Sat Aug 29 22:11:07 +0000 2015</td>\n",
       "      <td>Awake but tired. I need to sleep but my brain ...</td>\n",
       "      <td>1013187241</td>\n",
       "      <td>84</td>\n",
       "      <td>211</td>\n",
       "      <td>251</td>\n",
       "      <td>837</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>637696421077123073</td>\n",
       "      <td>Sat Aug 29 18:40:49 +0000 2015</td>\n",
       "      <td>RT @SewHQ: #Retro bears make perfect gifts and...</td>\n",
       "      <td>1013187241</td>\n",
       "      <td>84</td>\n",
       "      <td>211</td>\n",
       "      <td>251</td>\n",
       "      <td>837</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>637696327485366272</td>\n",
       "      <td>Sat Aug 29 18:40:26 +0000 2015</td>\n",
       "      <td>It’s hard to say whether packing lists are mak...</td>\n",
       "      <td>1013187241</td>\n",
       "      <td>84</td>\n",
       "      <td>211</td>\n",
       "      <td>251</td>\n",
       "      <td>837</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             post_id                    post_created  \\\n",
       "0           0  637894677824413696  Sun Aug 30 07:48:37 +0000 2015   \n",
       "1           1  637890384576778240  Sun Aug 30 07:31:33 +0000 2015   \n",
       "2           2  637749345908051968  Sat Aug 29 22:11:07 +0000 2015   \n",
       "3           3  637696421077123073  Sat Aug 29 18:40:49 +0000 2015   \n",
       "4           4  637696327485366272  Sat Aug 29 18:40:26 +0000 2015   \n",
       "\n",
       "                                           post_text     user_id  followers  \\\n",
       "0  It's just over 2 years since I was diagnosed w...  1013187241         84   \n",
       "1  It's Sunday, I need a break, so I'm planning t...  1013187241         84   \n",
       "2  Awake but tired. I need to sleep but my brain ...  1013187241         84   \n",
       "3  RT @SewHQ: #Retro bears make perfect gifts and...  1013187241         84   \n",
       "4  It’s hard to say whether packing lists are mak...  1013187241         84   \n",
       "\n",
       "   friends  favourites  statuses  retweets  label  \n",
       "0      211         251       837         0      1  \n",
       "1      211         251       837         1      1  \n",
       "2      211         251       837         0      1  \n",
       "3      211         251       837         2      1  \n",
       "4      211         251       837         1      1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tweets.csv')\n",
    "\n",
    "# explore the data characteristic using `df.describe()` or `df.info()`\n",
    "df.info()\n",
    "df.describe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13566cfc-ca98-4a22-89a0-c0774944d289",
   "metadata": {},
   "source": [
    "## 3. Extract emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d03e40d-0310-4654-9100-26f4442c17d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the function\n",
    "def extract_emoji(post_text):\n",
    "     return ''.join(c for c in post_text if c in [u\"\\U0001F600-\\U0001F64F\", u\"\\U0001F300-\\U0001F5FF\", u\"\\U0001F680-\\U0001F6FF\", u\"\\U0001F1E0-\\U0001F1FF\"])\n",
    "\n",
    "# apply the function to your dataframe\n",
    "df['emojis'] = df['post_text'].apply(extract_emoji)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d961f7-b745-4f4d-b516-68d9ef48dce2",
   "metadata": {},
   "source": [
    "## 4. Text Cleaning using Regular Expressions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec34e8bc-47ab-4bc9-a623-9436ecf6014b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the function\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)  # remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)  # remove mentions\n",
    "    text = re.sub(r'\\W', ' ', text)  # remove special characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # remove extra spaces\n",
    "    text = re.sub(r'#\\w+', '', text)  # remove hastags\n",
    "    text = re.sub(r'https?://\\S+|www.\\S+', '', text) # remove urls\n",
    "    return text.strip()\n",
    "\n",
    "# apply the function to your dataframe\n",
    "df['cleaned_text'] = df[\"post_text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec44d9f5-2311-4379-ba10-bd9a4ba87c8e",
   "metadata": {},
   "source": [
    "## 5. Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3bb995d2-845a-429e-ad81-b49911914de2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sentiment(cleaned_text):\n",
    "    analysis = TextBlob('cleaned_text')\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'\n",
    "\n",
    "sentiment = df[\"cleaned_text\"].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff6ee3d-825a-4ef0-9193-8d69e95b29ad",
   "metadata": {},
   "source": [
    "## 6. N-Grams and Phrase Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15c89b2-634b-4526-a67f-26806ca3aeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "def generate_ngrams(text, n):\n",
    "    tokens = text.split()\n",
    "    return list(ngrams(tokens, n))\n",
    "\n",
    "df[\"n_grams\"] =df[\"cleaned_text\"].apply(lambda x: generate_ngrams (x, n=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
